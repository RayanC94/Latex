\section{Implémentation}
\label{sec:implementation}

\subsection{Architecture Logicielle}

\subsubsection{Structure du Projet}

Notre implémentation suit une architecture modulaire favorisant la réutilisabilité et la maintenabilité du code :

\begin{lstlisting}[caption={Structure du projet}]
seed_vig_project/
├── data/
│   └── SEED-VIG/              # Dataset (non versionné)
│       ├── EEG_2Hz/
│       ├── EOG_feature/
│       └── perclos_labels/
├── src/
│   ├── __init__.py
│   ├── data_loader.py         # Chargement données
│   ├── models.py              # SVR, CCRF, CCNF
│   └── evaluation.py          # Métriques et visualisations
├── results/                   # Résultats générés
│   ├── figures/
│   ├── tables/
│   └── *.json
├── main.py                    # Pipeline principal
├── requirements.txt
└── README.md
\end{lstlisting}

\subsubsection{Technologies Utilisées}

\begin{table}[H]
\centering
\caption{Stack technologique du projet}
\label{tab:tech_stack}
\begin{tabular}{lll}
\toprule
\textbf{Composant} & \textbf{Bibliothèque} & \textbf{Version} \\
\midrule
Langage & Python & 3.9+ \\
ML/Régression & scikit-learn & 1.3.0 \\
Calcul numérique & NumPy & 1.24.0 \\
Traitement scientifique & SciPy & 1.11.0 \\
Visualisation & Matplotlib & 3.7.0 \\
Analyse données & Pandas & 2.0.0 \\
Barre de progression & tqdm & 4.65.0 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Module de Chargement des Données}

\subsubsection{Classe \texttt{SEEDVIGLoader}}

Le module \texttt{data\_loader.py} implémente une classe dédiée au chargement et à la préparation des données SEED-VIG :

\begin{lstlisting}[language=Python, caption={Interface du chargeur de données}]
class SEEDVIGLoader:
    """Chargeur pour le dataset SEED-VIG"""
    
    def __init__(self, data_root: str):
        """Initialise avec le chemin vers SEED-VIG"""
        self.data_root = Path(data_root)
        self.eeg_dir = self.data_root / 'EEG_2Hz'
        self.eog_dir = self.data_root / 'EOG_feature'
        self.perclos_dir = self.data_root / 'perclos_labels'
    
    def load_subject_data(self, subject_id: str, 
                         sample_rate: str = '2Hz',
                         eog_method: str = 'ica') -> Dict:
        """Charge EEG, EOG et PERCLOS pour un sujet"""
        # ...
    
    def prepare_features(self, data: Dict, 
                        use_posterior: bool = True) -> Tuple:
        """Prépare vecteur de features final"""
        # ...
\end{lstlisting}

\subsubsection{Sélection des Canaux EEG}

Conformément à l'article, nous utilisons les \textbf{canaux postérieurs} du système 10-20, qui ont démontré une sensibilité accrue aux variations de vigilance \cite{zheng2017vigilance} :

\begin{table}[H]
\centering
\caption{Canaux EEG utilisés (postérieurs)}
\label{tab:eeg_channels}
\begin{tabular}{lll}
\toprule
\textbf{Région} & \textbf{Canaux} & \textbf{Nombre} \\
\midrule
Pariétale & P3, Pz, P4, P7, P8 & 5 \\
Occipitale & O1, Oz, O2 & 3 \\
Temporale & T5, T6 & 2 \\
Pariéto-occipitale & PO3, PO4 & 2 \\
\midrule
\textbf{Total} & & \textbf{12} \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Justification :} Les régions postérieures (pariétales et occipitales) montrent une augmentation significative de l'activité theta et alpha lors de la somnolence, ainsi qu'une diminution du beta \cite{lal2003driver}.

\subsubsection{Préparation du Vecteur de Features}

Le pipeline de préparation des features suit les étapes suivantes :

\begin{enumerate}
    \item \textbf{Chargement :}
    \begin{itemize}
        \item Features EEG : Matrice \texttt{de\_lds} (885, 275) depuis fichiers \texttt{.mat}
        \item Features EOG : Matrice (885, 36) depuis fichiers \texttt{.mat}
        \item Labels PERCLOS : Vecteur (885,) depuis fichiers \texttt{.mat}
    \end{itemize}
    
    \item \textbf{Sélection de canaux :}
    \begin{lstlisting}[language=Python]
if use_posterior:
    # Canaux posterieurs uniquement
    eeg_features = eeg_features[:, posterior_indices]
    \end{lstlisting}
    
    \item \textbf{Concaténation :}
    \begin{equation}
    \mathbf{X} = [\mathbf{X}_{\text{EEG}}^{\text{post}}; \mathbf{X}_{\text{EOG}}] \in \mathbb{R}^{885 \times 311}
    \end{equation}
    
    \item \textbf{Normalisation :}
    \begin{lstlisting}[language=Python]
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_normalized = scaler.fit_transform(X)
# Moyenne = 0, Écart-type = 1 pour chaque feature
    \end{lstlisting}
\end{enumerate}

\textbf{Note importante :} Les features Differential Entropy sont \textbf{pré-calculées} dans le dataset SEED-VIG par les auteurs originaux. Nous les chargeons directement depuis les fichiers \texttt{.mat}, assurant ainsi une comparabilité exacte avec les résultats de l'article.

\subsection{Module des Modèles}

\subsubsection{Architecture des Classes}

Le module \texttt{models.py} implémente une hiérarchie de classes avec une interface commune :

\begin{figure}[H]
\centering
\begin{tikzpicture}[
    class/.style={rectangle, draw, fill=blue!10, text width=3cm, text centered, minimum height=1cm},
    arrow/.style={->, >=stealth, thick}
]
% Classe de base
\node[class] (base) at (0,0) {\texttt{VigilanceEstimator}};
\node[below=0.2cm of base, text width=3cm, font=\small] {Interface abstraite};

% Classes dérivées
\node[class] (svr) at (-4,-3) {\texttt{SVREstimator}};
\node[class] (ccrf) at (0,-3) {\texttt{CCRFEstimator}};
\node[class] (ccnf) at (4,-3) {\texttt{CCNFEstimator}};

% Flèches d'héritage
\draw[arrow] (svr) -- (base);
\draw[arrow] (ccrf) -- (base);
\draw[arrow] (ccnf) -- (base);

% Annotations
\node[below=0.2cm of svr, font=\small] {Kernel RBF};
\node[below=0.2cm of ccrf, font=\small] {Lissage temporel};
\node[below=0.2cm of ccnf, font=\small] {Non-linéaire};
\end{tikzpicture}
\caption{Hiérarchie des classes de modèles}
\label{fig:model_hierarchy}
\end{figure}

\subsubsection{Implémentation SVR}

Le SVR est implémenté en utilisant directement \texttt{sklearn.svm.SVR} :

\begin{lstlisting}[language=Python, caption={Implémentation SVR}]
from sklearn.svm import SVR

class SVREstimator(VigilanceEstimator):
    """Support Vector Regression avec kernel RBF"""
    
    def __init__(self, C: float = 10.0, gamma: float = 0.1, 
                 epsilon: float = 0.1):
        super().__init__()
        self.C = C
        self.gamma = gamma
        self.epsilon = epsilon
        self.model = SVR(
            kernel='rbf',
            C=self.C,
            gamma=self.gamma,
            epsilon=self.epsilon
        )
    
    def fit(self, X: np.ndarray, y: np.ndarray) -> 'SVREstimator':
        """Entraîne le modèle SVR"""
        self.model.fit(X, y)
        self.is_fitted = True
        return self
    
    def predict(self, X: np.ndarray) -> np.ndarray:
        """Prédit les valeurs PERCLOS"""
        if not self.is_fitted:
            raise ValueError("Modèle non entraîné")
        return self.model.predict(X)
\end{lstlisting}

\textbf{Hyperparamètres optimaux} (déterminés empiriquement) :
\begin{itemize}
    \item $C = 10.0$ : Compromis régularisation/précision
    \item $\gamma = 0.1$ : Largeur du noyau RBF
    \item $\epsilon = 0.1$ : Marge d'erreur tolérée
\end{itemize}

\subsubsection{Implémentation CCRF (Simplifiée)}

Le CCRF est implémenté comme une extension du SVR avec lissage temporel :

\begin{lstlisting}[language=Python, caption={Implémentation CCRF simplifiée}]
class CCRFEstimator(VigilanceEstimator):
    """CCRF simplifié: SVR + lissage temporel"""
    
    def __init__(self, C: float = 10.0, gamma: float = 0.1,
                 alpha: float = 1.0, beta: float = 0.1):
        super().__init__()
        self.base_model = SVREstimator(C=C, gamma=gamma)
        self.alpha = alpha  # Poids potentiel unaire
        self.beta = beta    # Poids potentiel temporel
    
    def predict(self, X: np.ndarray, 
                sequence_length: int = 7) -> np.ndarray:
        """Prédictions avec lissage temporel"""
        # 1. Prédictions SVR de base
        base_predictions = self.base_model.predict(X)
        
        # 2. Lissage temporel (approximation de Psi)
        smoothed = self._temporal_smoothing(
            base_predictions, 
            window_size=sequence_length
        )
        
        return np.clip(smoothed, 0, 1)
    
    def _temporal_smoothing(self, predictions: np.ndarray,
                           window_size: int) -> np.ndarray:
        """Moyenne mobile pondérée"""
        n = len(predictions)
        smoothed = np.zeros(n)
        
        for i in range(n):
            start = max(0, i - window_size + 1)
            window = predictions[start:i+1]
            
            # Poids exponentiels (plus récent = plus de poids)
            weights = np.exp(-self.beta * np.arange(len(window)))
            weights /= weights.sum()
            
            smoothed[i] = np.dot(window, weights)
        
        return smoothed
\end{lstlisting}

\textbf{Limitation reconnue :} Cette implémentation est une \textbf{approximation} du vrai CCRF. Le vrai CCRF utilise l'algorithme de Viterbi pour optimiser globalement la séquence, alors que notre approche applique un lissage local.

\subsubsection{Implémentation CCNF (Simplifiée)}

Le CCNF étend le CCRF avec une transformation non-linéaire :

\begin{lstlisting}[language=Python, caption={Implémentation CCNF simplifiée}]
class CCNFEstimator(VigilanceEstimator):
    """CCNF simplifié: CCRF + transformation non-linéaire"""
    
    def __init__(self, C: float = 10.0, gamma: float = 0.1,
                 alpha: float = 1.0, beta: float = 0.1,
                 n_neurons: int = 20):
        super().__init__()
        self.base_model = SVREstimator(C=C, gamma=gamma)
        self.alpha = alpha
        self.beta = beta
        self.n_neurons = n_neurons
    
    def _nonlinear_smoothing(self, predictions: np.ndarray,
                            window_size: int) -> np.ndarray:
        """Lissage avec transformation sigmoïde"""
        n = len(predictions)
        smoothed = np.zeros(n)
        
        for i in range(n):
            if i < window_size - 1:
                smoothed[i] = predictions[i]
            else:
                window = predictions[i-window_size+1:i+1]
                
                # Transformation sigmoïde
                transformed = 1 / (1 + np.exp(-self.alpha * 
                                  (window - window.mean())))
                
                # Moyenne pondérée
                weights = np.exp(-self.beta * np.arange(len(window)))
                weights /= weights.sum()
                
                smoothed[i] = np.dot(transformed, weights)
        
        return smoothed
\end{lstlisting}

\subsection{Protocole Expérimental}

\subsubsection{Pipeline d'Évaluation}

Le pipeline principal (\texttt{main.py}) exécute les étapes suivantes pour chaque sujet :

\begin{algorithm}[H]
\caption{Pipeline d'évaluation par sujet}
\label{alg:evaluation}
\begin{algorithmic}[1]
\FOR{chaque sujet $s \in \{1, \ldots, 23\}$}
    \STATE Charger données : $\mathbf{X}_s, \mathbf{y}_s \leftarrow$ \texttt{load\_subject\_data}($s$)
    \STATE Initialiser résultats : $R_s \leftarrow \{\}$
    \FOR{chaque modèle $m \in \{\text{SVR, CCRF, CCNF}\}$}
        \STATE Initialiser métriques : $\text{COR}_{\text{folds}} \leftarrow []$, $\text{RMSE}_{\text{folds}} \leftarrow []$
        \STATE Créer 5 folds temporels : $F \leftarrow$ \texttt{KFold}($n=5$, shuffle=True)
        \FOR{chaque fold $(i_{\text{train}}, i_{\text{val}}) \in F$}
            \STATE $\mathbf{X}_{\text{train}}, \mathbf{y}_{\text{train}} \leftarrow \mathbf{X}_s[i_{\text{train}}], \mathbf{y}_s[i_{\text{train}}]$
            \STATE $\mathbf{X}_{\text{val}}, \mathbf{y}_{\text{val}} \leftarrow \mathbf{X}_s[i_{\text{val}}], \mathbf{y}_s[i_{\text{val}}]$
            \STATE Normaliser : $\mathbf{X}_{\text{train}}, \mathbf{X}_{\text{val}} \leftarrow$ \texttt{StandardScaler}()
            \STATE Entraîner : $m.\text{fit}(\mathbf{X}_{\text{train}}, \mathbf{y}_{\text{train}})$
            \STATE Prédire : $\hat{\mathbf{y}}_{\text{val}} \leftarrow m.\text{predict}(\mathbf{X}_{\text{val}})$
            \STATE Calculer : $\text{COR} \leftarrow \text{pearsonr}(\mathbf{y}_{\text{val}}, \hat{\mathbf{y}}_{\text{val}})$
            \STATE Calculer : $\text{RMSE} \leftarrow \sqrt{\text{MSE}(\mathbf{y}_{\text{val}}, \hat{\mathbf{y}}_{\text{val}})}$
            \STATE $\text{COR}_{\text{folds}}.\text{append}(\text{COR})$
            \STATE $\text{RMSE}_{\text{folds}}.\text{append}(\text{RMSE})$
        \ENDFOR
        \STATE $R_s[m] \leftarrow \{\text{COR}: \text{mean}(\text{COR}_{\text{folds}}), \text{RMSE}: \text{mean}(\text{RMSE}_{\text{folds}})\}$
    \ENDFOR
\ENDFOR
\STATE Agréger sur tous les sujets : $R_{\text{global}} \leftarrow \text{aggregate}(R_1, \ldots, R_{23})$
\RETURN $R_{\text{global}}$
\end{algorithmic}
\end{algorithm}

\subsubsection{Validation Croisée Stratifiée}

Nous utilisons une validation croisée à 5 folds avec les caractéristiques suivantes :

\begin{itemize}
    \item \textbf{Nombre de folds :} 5 (80\% entraînement, 20\% validation)
    \item \textbf{Shuffle :} \texttt{True} avec \texttt{random\_state=42} (reproductibilité)
    \item \textbf{Stratification temporelle :} Préservation de la structure séquentielle au sein de chaque fold
    \item \textbf{Normalisation :} Appliquée séparément sur chaque fold (évite le data leakage)
\end{itemize}

\textbf{Justification du shuffle :} Bien que la vigilance soit un phénomène temporel, le shuffle est nécessaire pour :
\begin{enumerate}
    \item Éviter que tous les folds d'entraînement soient au début (période éveillée) et le fold de validation à la fin (période somnolente)
    \item Assurer une distribution équilibrée des niveaux de PERCLOS dans chaque fold
    \item Être cohérent avec la méthodologie de l'article original
\end{enumerate}

\subsection{Choix d'Implémentation et Compromis}

\subsubsection{Décisions Techniques}

\begin{table}[H]
\centering
\caption{Décisions d'implémentation et justifications}
\label{tab:implementation_choices}
\begin{tabular}{p{4cm}p{5cm}p{5cm}}
\toprule
\textbf{Aspect} & \textbf{Choix} & \textbf{Justification} \\
\midrule
Framework ML & scikit-learn & Standard, reproductible, documentation \\
\midrule
Langage & Python 3.9+ & Écosystème data science, lisibilité \\
\midrule
CCRF/CCNF & Approximation par lissage & Implémentation complète trop complexe \\
\midrule
Features & Pré-calculées (dataset) & Comparabilité exacte avec article \\
\midrule
Validation & 5-fold shuffle & Équilibre des niveaux de vigilance \\
\midrule
Normalisation & StandardScaler par fold & Évite data leakage \\
\midrule
Métriques & COR + RMSE & Conformité avec article \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Limitations Techniques Reconnues}

Nous reconnaissons les limitations suivantes de notre implémentation :

\begin{enumerate}
    \item \textbf{CCRF/CCNF Simplifiés :}
    \begin{itemize}
        \item Notre implémentation utilise un lissage local (fenêtre glissante)
        \item Le vrai CCRF optimise globalement via Viterbi
        \item Impact : RMSE plus élevé ($\sim$2× l'article), mais COR reste élevé (0.80)
    \end{itemize}
    
    \item \textbf{Hyperparamètres Fixes :}
    \begin{itemize}
        \item Pas d'optimisation par grid search (temps de calcul)
        \item Paramètres fixés empiriquement : $C=10$, $\gamma=0.1$
        \item Impact mineur : paramètres raisonnables, résultats cohérents
    \end{itemize}
    
    \item \textbf{Sélection de Canaux :}
    \begin{itemize}
        \item Utilisation des canaux postérieurs (comme article)
        \item Pas de comparaison systématique avec d'autres configurations
    \end{itemize}
\end{enumerate}

\subsubsection{Temps de Calcul}

Les expériences ont été réalisées sur un ordinateur portable standard :

\begin{itemize}
    \item \textbf{CPU :} Intel Core i7-10750H @ 2.6 GHz
    \item \textbf{RAM :} 16 GB
    \item \textbf{Temps total :} $\sim$30 minutes pour 23 sujets × 3 modèles × 5 folds
    \item \textbf{Temps par sujet :} $\sim$1.3 minutes
\end{itemize}

\textbf{Distribution du temps :}
\begin{itemize}
    \item SVR : 30\% (rapide, scikit-learn optimisé)
    \item CCRF : 35\% (lissage temporel additionnel)
    \item CCNF : 35\% (transformation non-linéaire)
\end{itemize}

\subsection{Reproductibilité}

Pour assurer la reproductibilité complète de nos résultats :

\begin{lstlisting}[language=Python, caption={Gestion de l'aléatoire}]
import numpy as np
import random

# Fix des seeds pour reproductibilité
RANDOM_SEED = 42
np.random.seed(RANDOM_SEED)
random.seed(RANDOM_SEED)

# Shuffle avec seed fixe dans KFold
kf = KFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)
\end{lstlisting}

\textbf{Vérification :} En relançant l'expérience avec les mêmes seeds, nous obtenons des résultats identiques à la précision machine près ($\Delta < 10^{-10}$).